#  BASIC CLUSTER SETTINGS (same for all)
spark.master                        yarn
spark.submit.deployMode             cluster

#  YARN INTEGRATION (same for all)
spark.yarn.populateHadoopClasspath  true
spark.yarn.am.memory                2g
spark.yarn.am.memoryOverhead        512m
spark.yarn.am.cores                 1

#  PYTHON ENVIRONMENT (same for all) 
spark.pyspark.python                python3
spark.pyspark.driver.python         python3

# ALLUXIO INTEGRATION (same for all)
spark.driver.extraClassPath   /usr/local/alluxio/client/alluxio-2.9.4-client.jar
spark.executor.extraClassPath /usr/local/alluxio/client/alluxio-2.9.4-client.jar

#  MEMORY MANAGEMENT (same for all)
spark.memory.fraction               0.6
spark.memory.storageFraction        0.4
spark.memory.offHeap.enabled        false

#  EXECUTOR SETTINGS (same for all) - optimized for 5 workers
spark.executor.memory               120g
spark.executor.cores                16
spark.driver.memory                 20g
spark.executor.memoryOverhead       30g

#  PARALLELISM (same for all) - optimized for 10 executors
spark.sql.shuffle.partitions        30
spark.default.parallelism           30

#  SHUFFLE & PERFORMANCE (same for all)
spark.shuffle.service.enabled       true
spark.speculation                   false
spark.serializer                    org.apache.spark.serializer.KryoSerializer
spark.kryo.unsafe                   true

#  NETWORK & TIMEOUTS (same for all)
spark.network.timeout               600s
spark.executor.heartbeatInterval    10s
spark.rpc.askTimeout                300s
spark.sql.broadcastTimeout          300s

#  SCHEDULER (same for all)
spark.scheduler.mode                FIFO
spark.scheduler.revive.interval     1s
spark.scheduler.maxRegisteredResourcesWaitingTime  30s
spark.scheduler.minRegisteredResourcesRatio        0.8
spark.scheduler.barrier.sync.timeout               365s

#  TASK MANAGEMENT (same for all)
spark.task.maxFailures              3
spark.stage.maxConsecutiveAttempts  8
spark.excludeOnFailure.enabled     false

#  DYNAMIC ALLOCATION (same for all)
spark.dynamicAllocation.enabled     false

#  SQL OPTIMIZATIONS (same for all)
spark.sql.adaptive.enabled          false
spark.sql.adaptive.coalescePartitions.enabled  false

#  PYTHON SPECIFIC (same for all)
spark.python.worker.reuse            false
spark.python.worker.memory           1g

#  LOGGING & MONITORING (same for all)
spark.eventLog.enabled              true
spark.eventLog.dir                  hdfs://master:9000/spark-logs
spark.history.fs.logDirectory       hdfs://master:9000/spark-logs
spark.ui.retainedJobs               100
spark.ui.retainedStages             200

#  ML/DISTRIBUTED TRAINING (same for all)
spark.ml.cache.enabled              true
spark.sql.execution.arrow.pyspark.enabled  true
spark.sql.execution.arrow.maxRecordsPerBatch  10000

#  LOCALITY PREFERENCES (same for all)
spark.locality.wait                 3s
spark.locality.wait.node            2s
spark.locality.wait.rack            0s

#  ENVIRONMENT VARIABLES (same for all)
spark.executorEnv.TORCH_DISTRIBUTED_DEBUG     DETAIL
spark.executorEnv.GLOO_LOG_LEVEL              DEBUG
spark.executorEnv.MPLCONFIGDIR                /tmp/matplotlib_cache
spark.executorEnv.OMP_NUM_THREADS             1